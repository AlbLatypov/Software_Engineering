# Лекторий по SRE: Цели мониторинга, логи и метрики

>Мониторинг - комплекс мероприятий, не инструменты

__Задачи мониторинга:__
- Детектирование сбоев
- Поиск причин сбоев при устранении
- Сбор информации для отладки
- Выявление трендов (сравнение прошлое и будущее, медленные тренды, становится приложение медленнее, быстрее и т.п.)

__Метрика__ - серия значений, привязанная к определенному промежутку времени.

__Схемы__: 
- оппозиционные, разделение точками `msk.hw.123`
- метрика с тэгами: `bytes {dc='MSK',type='HW'}`

>Мы называем _одна метрика_ - уникальное сочетание всех значений, всех тэгов.

__Типы метрик__:
- counter (все время увеличивается. На практике конечно уменьшается, если сбрасывается при рестарте)
- gauge - метрики, которые постоянное меняются, может как расти так и уменьшаться (температура cpu, memory etc). Частота сбора лучше 1 минута, чаще как правило, не информативно
- гистограммы: бывает 2х типов: а) время выполнения запросов, например. Статистика. б) квантили - медианы. Считают на статистике по последним запросам. (не понял, надо на практике). [Перцентиль](https://habr.com/ru/companies/tochka/articles/690814/). Говорит, что действительно сложно без практики понять, что это.

Модели:
- push (вытягивание)
- pull (некий сборщик, периодически ходит по приложениям)

>Типичный интервал сбора метрик - 1 минута.

Мало примеров. Смотрим дальше.

Tools:
- Prometheus
- Victoria Metrics
- Graphite
- InfluxDB
- Zabbix
- Nagios
- Datadog

Лидер это Grafana, отличная визуализация.
Задача одна, собрать числовые данные и дашбордами удобно и понятно доводить информацию.

Алертирование - при наступлении определенных событий, достижения крайнего значения - уведомление.

Проблемы: 
- со временем метрик становится очень много. Большое количество метрик может перегрузить централизованную систему сбора и обработки метрик. Хотя метрик может быть миллионы, но можно "настроить" так, что они метрики могут плодиться очень активно. Придумывает механизмы защиты от плодирования метрик. Если вы срелизили приложение, которое начинает плодировать кучу метрик, это может стать основанием для отката релиза, т.к. есть вероятность положить систему мониторинга, ибо это важно!

__Логи__ - это метрика времени+произвольная информация. 

На основании логов можем создавать свои метрики, считать что-либо. Вокруг логов выстраиваются некие автоматизированные процессы. За логами надо очень внимательно следить.

> На логах часто строят дополнительную логику, и изменение формата логов может ее поломать.

__Хранение логов__:
- в файлах на сервере
- systemd Jornal
- централизованные агрегаторы: elasticsearch, grafana Loki, Splunk

>Подход1. Отдельный сервер агрегатор (сайт кар) мониторит логи других серверов, понимает, что надо с ними что-то делать, собирает их и как-то обогащает дополнительной информацией (дописать название хоста или другое)
>Подход2. Приложение пишет в агрегатор логов __само__.

Если делать логирование неаккуратно, может потребять половину системных ресурсов. Парсер JSON достаточно небыстрый.

>Во время сбоев логов существенно больше, как количество, так и размер записей. 

__Подход надо тестировать, что будет происходить с системой логов во время сбоев!__

Мониторинг не менее важен, чем фичи приложения.

__Как уменьшают количество логов. Логичная выборка логов: статистика. Логировать не каждый запрос, а допустим каждый 10, 100, 1000. Определять, что действительно нужно. Иногда для формирования выводов о сбое достаточно 1-10% логов, если они типовые.__

Процессинг становится дорогим, похоже надо уметь доказывать важность системы логирования.


Трассировка запросов. Системы специализированные: opentracing, telemerty пытаются стандартизировать.

jaeger, Zipkin, elastic search


